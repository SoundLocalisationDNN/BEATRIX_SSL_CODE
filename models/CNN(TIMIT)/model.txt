class AudioRegressionCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.spec_conv = nn.Sequential(
            # Block 1
            nn.Conv2d(3,  64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64), nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64), nn.ReLU(),
            nn.MaxPool2d(2, 2),  # downsample

            # Block 2
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128), nn.ReLU(),
            nn.Conv2d(128,128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128), nn.ReLU(),
            nn.MaxPool2d(2, 2),

            # Block 3
            nn.Conv2d(128,256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256), nn.ReLU(),
            nn.Conv2d(256,256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256), nn.ReLU(),
            nn.MaxPool2d(2, 2),
        )

        # GCC branch: deeper
        self.gcc_conv = nn.Sequential(
            nn.Conv1d(1, 32, kernel_size=3, padding=1),
            nn.BatchNorm1d(32), nn.ReLU(),
            nn.Conv1d(32,64, kernel_size=3, padding=1),
            nn.BatchNorm1d(64), nn.ReLU(),
            nn.MaxPool1d(2,2),
            nn.Conv1d(64,128, kernel_size=3, padding=1),
            nn.BatchNorm1d(128), nn.ReLU(),
            nn.MaxPool1d(2,2),
        )

        # Fusion / regression: larger hidden
        fusion_dim = 256 + 128  # spec + gcc pooled dims
        self.fc = nn.Sequential(
            nn.Linear(fusion_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(64, 2),
        )

    def forward(self, spec_left, spec_right, gcc):
        # spec inputs: (B,1,F,T), gcc: (B,1,L)
        diff = spec_left - spec_right
        x = torch.cat([spec_left, spec_right, diff], dim=1)  # (B,3,F,T)
        h = self.spec_conv(x)                               # (B,256, F/8, T/8)
        f_spec = h.mean(dim=[2,3])                          # (B,256)

        g = self.gcc_conv(gcc)                              # (B,128, L/4)
        f_gcc = g.mean(dim=2)                               # (B,128)

        out = torch.cat([f_spec, f_gcc], dim=1)              # (B,384)
        return self.fc(out)                                 # (B,2)